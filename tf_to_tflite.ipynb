{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSgIzfY7UjyT",
        "outputId": "a23540f0-dcd4-48de-b498-a8e9fc38b306"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxoLEgwQWXYT"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# 1. Define paths\n",
        "model_path = \"/content/drive/MyDrive/Potato model/Model.h5\"  # Your .h5 model path\n",
        "model_dir = os.path.dirname(model_path)  # Get directory of .h5 file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cL4IKaxsWxap",
        "outputId": "9d3c34b0-245e-4645-9acb-28dbacde1819"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model loaded successfully\n",
            "Input shape: (None, 224, 224, 3)\n",
            "Saved artifact at '/tmp/tmp_ohfe4vu'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_layer')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  132550197277328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132550197275600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132550197276176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132550197274640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132550197275216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132550197273680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132550197274256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132550197272912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132550197272720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132550197278672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132550197273296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132550197279632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/convert.py:997: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Quantization successful! Model saved to: /content/drive/MyDrive/Potato model/Model_quant.tflite\n",
            "File size: 6412.8 KB\n"
          ]
        }
      ],
      "source": [
        "output_name = os.path.splitext(os.path.basename(model_path))[0] + \"_quant.tflite\"  # New filename\n",
        "tflite_path = os.path.join(model_dir, output_name)  # Full output path\n",
        "\n",
        "# 2. Load the model\n",
        "try:\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "    print(\" Model loaded successfully\")\n",
        "    print(f\"Input shape: {model.input_shape}\")  # Verify expected input shape\n",
        "except Exception as e:\n",
        "    print(f\" Failed to load model: {e}\")\n",
        "    raise\n",
        "\n",
        "# 3. Representative dataset (adjust shape if different from 224x224x3)\n",
        "def representative_dataset():\n",
        "    input_shape = model.input_shape[1:]  # Get (224, 224, 3) from (None, 224, 224, 3)\n",
        "    for _ in range(100):  # 100 representative samples\n",
        "        yield [np.random.rand(1, *input_shape).astype(np.float32)]\n",
        "\n",
        "# 4. Configure converter\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset\n",
        "converter.target_spec.supported_ops = [\n",
        "    tf.lite.OpsSet.TFLITE_BUILTINS_INT8,\n",
        "    tf.lite.OpsSet.SELECT_TF_OPS  # Fallback for unsupported ops\n",
        "]\n",
        "\n",
        "# 5. Convert and save\n",
        "try:\n",
        "    tflite_model = converter.convert()\n",
        "    with open(tflite_path, \"wb\") as f:\n",
        "        f.write(tflite_model)\n",
        "    print(f\"Quantization successful! Model saved to: {tflite_path}\")\n",
        "    print(f\"File size: {os.path.getsize(tflite_path)/1024:.1f} KB\")\n",
        "except Exception as e:\n",
        "    print(f\"Conversion failed: {e}\")\n",
        "    if \"representative_dataset\" in str(e):\n",
        "        print(\"Tip: Check if your representative dataset matches the model's input shape\")\n",
        "    raise"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
